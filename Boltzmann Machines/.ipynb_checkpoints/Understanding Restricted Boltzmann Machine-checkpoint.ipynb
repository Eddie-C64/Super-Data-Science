{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Data processing and loading Depedencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This file creates a Restricted Boltzmann Machine.\n",
    "# This file only runs of python2.7 via anaconda\n",
    "# Part 1 - Data Processing\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "movies = pd.read_csv('ml-1m/movies.dat', sep='::', header=None, engine='python', encoding='latin-1')\n",
    "users = pd.read_csv('ml-1m/users.dat', sep='::', header=None, engine='python', encoding='latin-1')\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep='::', header=None, engine='python', encoding='latin-1')\n",
    "\n",
    "training_set = pd.read_csv('ml-100k/u1.base', sep=\"\\t\")\n",
    "training_set = np.array(training_set, dtype='int')\n",
    "\n",
    "test_set = pd.read_csv('ml-100k/u1.test', sep=\"\\t\")\n",
    "test_set = np.array(test_set, dtype='int')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Preparing Variables for the RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Part 2 - Preparing Variable for Boltzmann Machine\n",
    "nb_users = int(max(max(training_set[:, 0]), max(test_set[:, 0])))\n",
    "nb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1])))\n",
    "\n",
    "\n",
    "def convert(data):\n",
    "\n",
    "    new_data = []\n",
    "\n",
    "    for id_users in range(1, nb_users):\n",
    "        id_movies = data[:, 1][data[:, 0] == id_users]\n",
    "        id_rating = data[:, 2][data[:, 0] == id_users]\n",
    "        movie_ratings = np.zeros(nb_movies)\n",
    "        movie_ratings[id_movies - 1] = id_rating\n",
    "        new_data.append(list(movie_ratings))\n",
    "\n",
    "    return new_data\n",
    "\n",
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert Data to PyTorch Torch Tensors\n",
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)\n",
    "\n",
    "training_set[training_set == 0] = -1\n",
    "training_set[training_set == 1] = 0\n",
    "training_set[training_set == 2] = 0\n",
    "training_set[training_set >= 3] = 1\n",
    "\n",
    "test_set[test_set == 0] = -1\n",
    "test_set[test_set == 1] = 0\n",
    "test_set[test_set == 2] = 0\n",
    "test_set[test_set >= 3] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Creating the Architecture of the RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RBM(object):\n",
    "    def __init__(self, num_visible, num_hidden):\n",
    "        self.Weights = torch.randn(num_visible, num_hidden)\n",
    "        self.hidden_layer = torch.randn(1, num_hidden)  # Create single hidden layer\n",
    "        self.visible_layer = torch.randn(1, num_visible)  # Only a single visible layer\n",
    "\n",
    "    def sample_hidden(self, x):\n",
    "        wx = torch.mm(x, self.Weights)\n",
    "        activation = wx + self.hidden_layer.expand_as(wx)\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "\n",
    "    def sample_visible(self, x):\n",
    "        wy = torch.mm(x, self.Weights.t())\n",
    "        activation = wy + self.visible_layer.expand_as(wy)\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "\n",
    "    def train(self, v_zero, v_k_th, prob_h_vec_0, prob_h_vec_k):\n",
    "        self.Weights += torch.mm(v_zero.t(), prob_h_vec_0) - torch.mm(v_k_th.t(), prob_h_vec_k)\n",
    "        self.visible_layer += torch.sum((v_zero - v_k_th), 0)\n",
    "        self.hidden_layer += torch.sum((prob_h_vec_0 - prob_h_vec_k), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 - Set Parameters & Training the RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: 0.339933507542\n",
      "epoch: 2 loss: 0.258209253527\n",
      "epoch: 3 loss: 0.249506544238\n",
      "epoch: 4 loss: 0.24227295324\n",
      "epoch: 5 loss: 0.248805495263\n",
      "epoch: 6 loss: 0.248251381443\n",
      "epoch: 7 loss: 0.249992162913\n",
      "epoch: 8 loss: 0.249160347992\n",
      "epoch: 9 loss: 0.246186599672\n",
      "epoch: 10 loss: 0.245613504523\n"
     ]
    }
   ],
   "source": [
    "# Hyper Parameters\n",
    "nv = len(training_set[0])  # The number is chosen by how many columns for data\n",
    "nh = 100  # len(movies[0]) is too large, but sample to limit 100 features\n",
    "batch_size = 100\n",
    "nb_epoch = 10\n",
    "\n",
    "rbm = RBM(nv, nh)\n",
    "\n",
    "# Part 5 - Train the model\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    training_loss = 0.0\n",
    "    scaler_value = 0.0\n",
    "    for id_user in range(0, nb_users-batch_size, 100):\n",
    "        vk = training_set[id_user:id_user+batch_size]  # Kth node\n",
    "        v0 = training_set[id_user:id_user+batch_size]  # visible node of kth position\n",
    "        ph0, _ = rbm.sample_hidden(v0)\n",
    "\n",
    "        # Apply Random Walk of a Monte Carlo Technique\n",
    "        for k in range(nb_epoch):\n",
    "            _, hk = rbm.sample_hidden(vk)\n",
    "            _, vk = rbm.sample_visible(hk)\n",
    "            vk[v0 < 0] = v0[v0 < 0]\n",
    "\n",
    "        phk, _ = rbm.sample_hidden(vk)\n",
    "        rbm.train(v0, vk, ph0, phk)\n",
    "        training_loss += torch.mean(torch.abs(v0[v0 >= 0] - vk[v0 >= 0]))\n",
    "        scaler_value += 1.\n",
    "    print \"epoch: \" + str(epoch) + \" loss: \" + str(training_loss/scaler_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6 - Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.221818634635\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "test_s = 0.0\n",
    "scale_count = 1.0\n",
    "for id_user in range(nb_users):\n",
    "    try:\n",
    "        v = test_set[id_user:id_user+batch_size]  # Kth node\n",
    "        vt = training_set[id_user:id_user+batch_size]  # visible node target position\n",
    "\n",
    "        # Apply Blind Walk of a Monte Carlo Technique\n",
    "        if len(vt[vt >= 0]) > 0:\n",
    "            _, ht = rbm.sample_hidden(vt)\n",
    "            _, vt = rbm.sample_visible(ht)\n",
    "            test_loss += torch.mean(torch.abs(v0[v0 >= 0] - vt[v0 >= 0]))\n",
    "            test_s += 1.0\n",
    "            scale_count += 1.0\n",
    "    except (RuntimeError, ValueError):\n",
    "        continue\n",
    "print \"Test Loss: \" + str(test_loss/ scale_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conlusion:\n",
    "It seems the model is predicting with an accuracy of about 23% on the test data. Overall it is not that bad of a prediction. Further research must be done to predict a higher accuary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
